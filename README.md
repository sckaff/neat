NEUROEVOLUTION
——————————————————
- Even if I achieve consciousness, it is not quantum. Algorithm’s pseudo randomness (on EC) at best.
- How entropy and information works on generative AI
- Novelty reward (Novelty creates a gradient of behavioral differences — maximizing is done without any intent of search termination or direction.) + Fitness reward
    - Novelty (exploration) -> Fitness (exploitation)… 
    - Reward novelty.. define novelty beforehand
- Bootstrap creativity. It’s almost like humanity prioritized creativity as a highly demanded feature. We should do the same.
- AI that asks the right questions
- Predict future then optimize
- EC as the mind, DL as the body, energy as the soul
- Capacity of reasoning should not impact the genetic code that determines such capacity. The capacity of reasoning itself is subject to change.
    - An expensive reasoning to make the architecture itself
    - And a cheap reasoning to live and see its fitness
- Mindless intelligence. A purely numerical solution beat the best chess player at the time, that could tell you “the way he plays”. 
- "To find Nash equilibrium, have every player in a non-cooperative game reveal their strategies to one another. If no player changes their strategy after knowing all others' strategies, a Nash equilibrium exists.”
- Genotype (Encoding) and Phenotype (Decoding)
- Optimize things that are non-differentiable and have a very long time horizon (meta learning, sparse exploration problems)
- Competitive Coevolution = Adversarial Training | Cooperative Coevolution = ?
- EVOLUTION ON THE OUTER-LOOP, LEARNING IN THE INNER LOOP
- Set: Environment and Genetics (doesn’t have to be binary… btw. Why 4 GTCA?)
- Neuroevolution
    - Q* was indeed a leak
        - Recognition of the importance of not over-focusing on specific features at the expense of overall functionality
        - The prospect of developing an ever-complex system sustained only by energy input.
        - Similarities between “genotype (encoding) and phenotype (decoding)“ ?
        - Evolutionary Computation (EC) has a broad search space; Deep Learning (DL) offers robust specific learning.
- How did edward edberg get his opportunity to do research at the university of chicago?
- The prospect of developing an ever-complex system sustained only by energy input.
- Advocacy for the benefits of multimodal deep learning agents in understanding complex biological systems. (Ask ChatGPT is that similar to multi objective optimization?)
- Any benefit pairing it with Reinforcement Learning?
- The necessity for a broader theoretical understanding of learning in machines.
- moving beyond supervised learning. (Ask ChatGPT - Why? What can we learn with unsupervised learning that supervised doesnt offer?)
- Revisit Nash equilibrium? Achieve Open-ended evolution ? Never-ending algorithm? Exploration vs exploitation?
- Updating weights but also nodes gives us a new degree of freedom (node creation and destruction?)
- The opportunity that a machine in which creativity emerges can be ground-breaking.  
